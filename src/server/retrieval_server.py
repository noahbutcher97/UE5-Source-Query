# python
# ===== File: RetrievalServer.py =====
import os, json, argparse
from http.server import BaseHTTPRequestHandler, ThreadingHTTPServer
from urllib.parse import urlparse, parse_qs
from pathlib import Path
import numpy as np
from sentence_transformers import SentenceTransformer

SCRIPT_DIR = Path(__file__).parent
VECTORS = SCRIPT_DIR / "vector_store.npz"
META = SCRIPT_DIR / "vector_meta.json"
DEFAULT_EMBED_MODEL = os.getenv("EMBED_MODEL", "sentence-transformers/all-MiniLM-L6-v2")

class RetrievalCore:
    def __init__(self, embed_model: str):
        if not VECTORS.exists() or not META.exists():
            raise SystemExit("Missing vector store. Run: python BuildEmbeddings.py --use-index")
        self.embeddings = np.load(VECTORS, mmap_mode="r")["embeddings"]
        self.meta = json.loads(META.read_text())["items"]
        self.model = SentenceTransformer(embed_model)
        dim = self.model.get_sentence_embedding_dimension()
        if self.embeddings.shape[1] != dim:
            raise SystemExit(f"Embedding dim mismatch: store={self.embeddings.shape[1]} model={dim}")

    def embed(self, text: str) -> np.ndarray:
        return self.model.encode([text], convert_to_numpy=True, normalize_embeddings=True)[0]

    def search(self, query: str, top_k: int, extensions: set[str], pattern: str):
        qvec = self.embed(query)
        filtered_indices = []
        for idx, m in enumerate(self.meta):
            p = m["path"]
            if extensions and Path(p).suffix.lower() not in extensions:
                continue
            if pattern and pattern.lower() not in p.lower():
                continue
            filtered_indices.append(idx)
        if not filtered_indices:
            return [], []
        embs = self.embeddings[filtered_indices]
        sims = embs @ qvec
        order = np.argsort(-sims)[:top_k]
        hits = []
        context_parts = []
        for rank_pos, local_i in enumerate(order, 1):
            global_idx = filtered_indices[local_i]
            m = self.meta[global_idx].copy()
            m["score"] = float(sims[local_i])
            hits.append(m)
            snippet = self._load_chunk(m)
            context_parts.append(f"// [{rank_pos}] score={m['score']:.3f} path={m['path']} chunk={m['chunk_index']+1}/{m['total_chunks']}\n{snippet}\n")
        return hits, context_parts

    def _load_chunk(self, record: dict) -> str:
        try:
            text = Path(record["path"]).read_text(encoding="utf-8", errors="ignore")
        except OSError:
            return ""
        # These values should match BuildEmbeddings.py
        chunk_size = record.get("chunk_size", 1500)
        overlap = record.get("chunk_overlap", 200)
        step = chunk_size - overlap
        start = record["chunk_index"] * step
        return text[start:start + chunk_size]

    def load_file(self, path: str) -> str:
        p = Path(path)
        if not p.exists() or not p.is_file():
            return ""
        try:
            return p.read_text(encoding="utf-8", errors="ignore")
        except OSError:
            return ""

core: RetrievalCore | None = None

def parse_extensions(raw: str) -> set[str]:
    if not raw: return set()
    out = {("." + e.strip()) if not e.strip().startswith(".") else e.strip() for e in raw.split(",") if e.strip()}
    return out

class Handler(BaseHTTPRequestHandler):
    def do_GET(self):
        parsed = urlparse(self.path)
        if parsed.path == "/health":
            return self._json({"status": "ok"})
        elif parsed.path == "/search":
            qs = parse_qs(parsed.query)
            q = qs.get("q", [""])[0].strip()
            if not q: return self._json({"error": "missing q"}, code=400)
            top_k = int(qs.get("top_k", ["6"])[0])
            pattern = qs.get("pattern", [""])[0].strip()
            exts = parse_extensions(qs.get("extensions", [""])[0])
            hits, context_parts = core.search(q, top_k, exts, pattern)
            context_block = ("// Context below generated by retrieval server\n" + "\n".join(context_parts) + "\n// End context\n")
            return self._json({"query": q, "top_k": top_k, "matches": hits, "context": context_block})
        elif parsed.path == "/file":
            qs = parse_qs(parsed.query)
            path = qs.get("path", [""])[0]
            if not path: return self._json({"error": "missing path"}, code=400)
            content = core.load_file(path)
            if not content: return self._json({"error": "not found or unreadable"}, code=404)
            return self._json({"path": path, "content": content})
        else:
            self._json({"error": "not found"}, code=404)

    def log_message(self, *a): pass

    def _json(self, obj, code=200):
        data = json.dumps(obj, indent=2).encode("utf-8")
        self.send_response(code)
        self.send_header("Content-Type", "application/json; charset=utf-8")
        self.send_header("Access-Control-Allow-Origin", "*")
        self.send_header("Cache-Control", "no-store")
        self.end_headers()
        self.wfile.write(data)

def serve(host: str, port: int):
    server = ThreadingHTTPServer((host, port), Handler)
    print(f"Retrieval server listening on http://{host}:{port}")
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        pass
    finally:
        server.server_close()

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--host", default="127.0.0.1")
    ap.add_argument("--port", type=int, default=8765)
    ap.add_argument("--model", default=DEFAULT_EMBED_MODEL)
    args = ap.parse_args()
    global core
    core = RetrievalCore(args.model)
    serve(args.host, args.port)

if __name__ == "__main__":
    main()
